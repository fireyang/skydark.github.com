---
layout: post
title: "有关 AI 的辩论研讨会记录"
category: thinking
excerpt: "计算机到底能做什么？人工智能的理论限度"
tags: [AI, 学业]
---
{% include JB/setup %}

<span markdown="1">***draft mode 1***</span>{:.label .label-warning}

<div markdown="1">

这两天(11日-12日)在我校办的一个和 AI 有关的会议，
题目就是“计算机到底能做什么？——人工智能的理论限度”。
因为觉得很有趣，遂记录如下。

> 我的看法会这样记录。
{:.alert .alert-info}

---

主要围绕六个问题，它们是：

1. 如果要构建像人类一样思维的机器，成功的标准是什么？图灵测验吗？
2. 计算机是个形式系统，而哥德尔不完全性说明形式系统不能证明某些真命题。这是否说明人的某些知识是计算机永远不能得到的？是否所有知识都能形式化？自指性知识呢？
3. 计算机能处理符号，但它能真正理解符号所代表的意义吗(意义指称能力问题)？如果人的概念依赖于人类的躯体和动机(涉身性认知)，那计算机怎么可能掌握它们？
4. 如果计算机只能遵循给定的程序运行(预先设定的程序)，那它怎么可能有创造性和灵活性？
5. 计算机是理性的，而情感和其他非理性因素在人的思维活动中扮演重要角色(倾向性指导作用)。这是否说明计算机不能像人一样思维？
6. 意识的本性是什么(特别是自我意识)？机器能够拥有意识能力吗？

---

说是辩论，自然有辩论双方。
因为没有正反方一说(虽然明显有是否主流的区别……)，所以称之为攻守方。
攻的是认为人工智能可实现的王培教授(美国天普大学)，
守的是认为人工智能永远不可能实现的周昌乐教授(厦门大学)。
当然，在两人介绍彼此观点后，反而感觉攻守完全反过来了……

两位主辩经历颇为传奇，一位是侯世达的弟子，一位是马希文的传人；一位专注一个方向数十年，一个每年做十个方向(雾)。 
两位非常清楚下面一桌围观群众和一排不明真相的围观群众对他们彼此掐架喜闻乐见，因此纷纷表示会把自己做成一个大靶子供大家射击……

---

第一天上午除了一些致词外，就是两名主辩亮明自己观点。下午讨论了前两个问题。
另外必须得说，茶歇的食品很受欢迎，另外贵校学生请自行解决午餐晚餐bgm38……

伪守真攻的周昌乐教授先介绍自己的观点。开篇就在讲心识和古印度的唯识学，我们几个不明真相的围观群众纷纷表示虽不明但觉厉……
随后伪攻真守的王培教授阐述的观点，这些我倒是基本比较熟悉，因为这学期一直在旁听他的课。另外估计是他这学期上课上多了，做报告的时候中间还会掺杂着“关于这一点同学们可能会说”的口头禅……233

我想就记下周教授的观点，然后批注上我对王培的观点的理解好了(好的，说明我是王培派的233)。

*TODO*
{:.label .label-warning}

1. 图灵测试应该是人工智能的标准。但它不是那么容易能被通过的，关键在于问者怎样提问。
    一个经典的例子：问人/机器TA的年龄。问一次，计算机和人难以区分；问多次，人可能会不耐烦；问更多次，人感到不耐烦的表达也不见得相同。而计算机难以实现——当然，计算机可以故意模拟这种情况，然而人总可以更改提问的方式，让计算机设计者被动的跟着问题跑。
    最后，我们应当遵循摩根准则，即一个现象如果能用简单的方式解释，就不应该选择复杂的解释。如果可以用简单的条件判断机制等解释机器的行为，就不应该用“它具有智能”这种更复杂的机制来解释。

2. 哥德尔定理重点体现了矛盾的必然。比如审美中的复调艺术，体现的是一种矛盾中的美。而机器是没法从这种矛盾中理解的。
    (还举了自组织自涌现，以及钵中之脑的例子，不是很理解与主题的关联。)

3. 意义指称的难点在于自然语言是元语言与对象语言揉合的。周教授举的例子是一个古诗，古诗的开头是“长亭……”，然而教授写的时候只是把“亭”字写的很长，这种隐含的表达人是可以理解的。
    类似的另一个例子是对杜牧的《清明》进行解读。假如不知道这是七言诗，那么人完全可以断出一个剧本来。而机器总是先分词再理解语义的。
    最为甚的，所谓的终极指称能力——悟(周教授研究过三年禅宗)，是所谓只可意会不可言说的，是无法用符号表达的。

4. 预先设定的程序无法产生智能，基本都是现在这些机器学习这类的例子……(略走神不确定)

5. 情感举了日本那个带表情的机器人的例子。

6. 主观体验——蛇神(写作zombie)。

---

下午的会议开始讨论前两个问题。都是先一位教授做一刻钟的专题报告，然后开始混战。

第一个问题是：

***如果要构建像人类一样思维的机器，成功的标准是什么？图灵测验吗？***

P.S.: 老板显然对第一个问题没啥兴趣(“我们搞 AI 的就是想来听听你们搞哲学的的观点开拓开拓思路”)，于是准时在茶歇时刻才出现，并且在茶歇后在第二个问题上大杀特杀……

第一个问题首先是智能科学系的王立威教授的专题报告《人工智能所需要的要素》。

首先他认为智能是一种相对环境的实现目的的能力。
他认为图灵机是无智能的，因为图灵机适应的环境过于简单。
下棋程序也是无智能的，因为其环境也相对稳定。

> 我觉得“图灵机适应的环境简单”这句话是很奇怪的。
> 作为一种抽象机，它的纸带能表达数字，其实也能表达各种环境。
> 
> 这一点我用王培的观点来解释，“是一个看问题的层面的问题”。
> 比如从神经元的角度看，我们是看不出人的智能的，尽管智能最终还是靠它们构成的。我们只有从更高的角度才能看到智能。
> 我想图灵机也是一样。
{:.alert .alert-info}

他还强调图灵机的限制在于其带符号等结构是固定不可增长的(表达)，且具有局部计算性(计算)。
他认为局部计算性是不应抛弃的，但表达应有所提升，应允许有限但可任意增长的符号集、状态等。

> 但这种扩充仍然不会改变图灵机的能力。
{:.alert .alert-info}

*TODO*
{:.label .label-warning}

关于图灵测验的问题。

图灵测验本身的构成。

行为主义。他心知。

人是唯一智能？

对变化的适应性。

通用性。

---

*TODO*
{:.label .label-warning}

第二个问题。

逻辑系统。

选择一个好的形式系统。

形式化、数字化、数据、知识。

禅宗。

</div>
{:.alert .well}
